{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5198bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                              #in the name of creator Ali\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# adress\n",
    "base_url = \"https://www.dadrah.ir/\"\n",
    "list_url = \"https://www.dadrah.ir/consulting-catalog.php?page=\"\n",
    "\n",
    "# Header settings for requests\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# lists for save data\n",
    "data = []\n",
    "\n",
    "# max of lops\n",
    "max_retries = 5\n",
    "\n",
    "\n",
    "#Number of pages to process between each save\n",
    "\n",
    "save_interval = 100  \n",
    "\n",
    "# Circle to navigate different pages of the site\n",
    "\n",
    "for page in range(1,2):                            # Change to the number of  pages you want\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "           #request to website\n",
    "            response = requests.get(list_url + str(page), headers=headers, timeout=10)\n",
    "            time.sleep(2) \n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                \n",
    "                #  export date\n",
    "                calendar_icons = soup.find_all('i', class_='fa fa-calendar')\n",
    "                for calendar_icon in calendar_icons:\n",
    "                    date_span = calendar_icon.find_parent('span', class_='pull-right')\n",
    "                    if date_span:\n",
    "                        persian_date_text = date_span.text.strip()\n",
    "                    else:\n",
    "                        persian_date_text = \"Date not found\"\n",
    "\n",
    "                # link and element\n",
    "                question_links = soup.find_all('a', href=True, string=\"ادامه ی مطلب و پاسخ ها ...\")\n",
    "                \n",
    "                for link in question_links:\n",
    "                    question_url = base_url + link['href']  # ساخت URL کامل برای دسترسی به صفحه سوال\n",
    "                    question_response = requests.get(question_url, headers=headers, timeout=10)\n",
    "                    \n",
    "                    if question_response.status_code == 200:\n",
    "                        question_soup = BeautifulSoup(question_response.text, 'html.parser')\n",
    "                        \n",
    "                        # subject\n",
    "                        question_subject = question_soup.find('a', class_='btn btn-info tags')\n",
    "                        subject_text = question_subject.text.strip() if question_subject else \"Not found\"\n",
    "                        \n",
    "                        # question\n",
    "                        full_question = question_soup.find('p', attrs={'style': 'text-align:justify;'})\n",
    "                        question_text = full_question.text.strip() if full_question else \"Not found\"\n",
    "                        \n",
    "                        # answers\n",
    "                        answers = question_soup.find_all('p', class_='text-justify text-primary')\n",
    "                        for answer in answers:\n",
    "                            answer_text = answer.text.strip()\n",
    "                            \n",
    "                            # dictionary\n",
    "                            data.append({\n",
    "                                \"Subject\": subject_text,\n",
    "                                \"Question\": question_text,\n",
    "                                \"Question Date\": persian_date_text,\n",
    "                                \"Answer\": answer_text,\n",
    "                            })\n",
    "                    else:\n",
    "                        print(f\"Failed to retrieve the question page: {question_url}\")\n",
    "                break  \n",
    "            else:\n",
    "                print(f\"Error: Could not retrieve page {page}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error on page {page}, attempt {attempt+1}: {e}\")\n",
    "            time.sleep(5)  \n",
    "    else:\n",
    "        print(f\"Failed to retrieve page {page} after {max_retries} attempts\")\n",
    "\n",
    "    # Save data at specified intervals\n",
    "    if page % save_interval == 0:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_excel(f\"extracted_data_temp_page_{page}.xlsx\", index=False, engine='openpyxl')\n",
    "        print(f\"Data saved after processing {page} pages\")\n",
    "\n",
    "# final save\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel(\"extracted_data_with_subject.akhar123.xlsx\", index=False, engine='openpyxl')\n",
    "\n",
    "print(\"Final data has been successfully saved to extracted_data_with_subject.akhar.xlsx\")\n",
    "\n",
    "\n",
    "#                                             رندان تشنه لب را آبی نمیدهد کس  \n",
    "#                                            گویی ولی شناسان رفتند از این ولایت\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8de85e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be11043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
